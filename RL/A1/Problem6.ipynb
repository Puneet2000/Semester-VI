{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6: Value Iteration\n",
    "Puneet Mangla (CS17BTECH11029)\n",
    "\n",
    "Observation - Enviornment is deterministic, so value-iteration becomes\n",
    "\n",
    "$V_{k+1}(s) = max_a [R^a_{ss'} + \\gamma V_k(s')]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "N = 6 \n",
    "action = [0,1] # 0 left, 1 right\n",
    "S_ = [{0:0,1:1}, {0:0,1:2}, {0:1,1:3}, {0:2,1:4},{0:3,1:5},{0:5,1:5}] #next states for every action\n",
    "\n",
    "R  = np.array([0,0,0,0,0,10])\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op(R,gamma):\n",
    "    K = 100\n",
    "    V = np.zeros(N)\n",
    "    for _ in range(K):\n",
    "        V_new = np.copy(V)\n",
    "        V_new[N-1] = R[N-1]\n",
    "        for s in range(N-1):\n",
    "            V_new[s] = -np.inf\n",
    "            vl = R[s] + gamma*V[S_[s][0]]\n",
    "            vr = R[s] + gamma*V[S_[s][1]]\n",
    "            V_new[s] = max(vl,vr)\n",
    "        V = np.copy(V_new)\n",
    "    print('Value Function',V)\n",
    "    policy = []\n",
    "    for s in range(N-1):\n",
    "        v_l = R[s] + gamma*V[S_[s][0]]\n",
    "        v_r = R[s] + gamma*V[S_[s][1]]\n",
    "        if v_l > v_r:\n",
    "            policy.append('Left')\n",
    "        else:\n",
    "            policy.append('Right')\n",
    "    policy.append('Stay')\n",
    "    print(policy)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute value function represents the average rolling to reach state W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function [10. 10. 10. 10. 10. 10.]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Value Function [ 5.9049  6.561   7.29    8.1     9.     10.    ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Value Function [ 0.3125  0.625   1.25    2.5     5.     10.    ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Value Function [1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n"
     ]
    }
   ],
   "source": [
    "# 6(a)\n",
    "op(R,1)\n",
    "\n",
    "# 6(b)\n",
    "op(R,0.9)\n",
    "op(R,0.5)\n",
    "op(R,0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimal policy remains same, though value function changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant -20\n",
      "Value Function [-87.8069 -75.341  -61.49   -46.1    -29.     -10.    ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Constant -15\n",
      "Value Function [-64.37895 -54.8655  -44.295   -32.55    -19.5      -5.     ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Constant -10\n",
      "Value Function [-40.951 -34.39  -27.1   -19.    -10.      0.   ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Constant -5\n",
      "Value Function [-17.52305 -13.9145   -9.905    -5.45     -0.5       5.     ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Constant 0\n",
      "Value Function [ 5.9049  6.561   7.29    8.1     9.     10.    ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Right', 'Stay']\n",
      "Constant 5\n",
      "Value Function [49.99896706 49.99896706 49.99896706 49.99896706 49.99896706 15.        ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Left', 'Stay']\n",
      "Constant 10\n",
      "Value Function [99.99763899 99.99763899 99.99763899 99.99763899 99.99763899 20.        ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Left', 'Stay']\n",
      "Constant 15\n",
      "Value Function [149.99631092 149.99631092 149.99631092 149.99631092 149.99631092\n",
      "  25.        ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Left', 'Stay']\n",
      "Constant 20\n",
      "Value Function [199.99498285 199.99498285 199.99498285 199.99498285 199.99498285\n",
      "  30.        ]\n",
      "['Right', 'Right', 'Right', 'Right', 'Left', 'Stay']\n"
     ]
    }
   ],
   "source": [
    "# 6(c)\n",
    "cs = [-20,-15,-10,-5,0,5,10,15,20]\n",
    "for c in cs:\n",
    "    print('Constant',c)\n",
    "    op(R+c,0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $c \\leq 10$, The optimal policy is always to move right. But as c becomes greater than 10, the policy changes to move left at $s_5$. It will cause a never-ending process leading to large rewards ( infinte in case of $\\gamma=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
